{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(x, y, learning_rate, m):\n",
    "    k = x.shape[0]\n",
    "    l = x.shape[1]\n",
    "    slope_m = np.zeros(l)\n",
    "    for i in range(k):\n",
    "        for j in range(l):\n",
    "            slope_m[j] += (2/k)*x[i][j]*((x[i].dot(m)) - y[i])\n",
    "        #if i%32 == 0:\n",
    "    m = m - learning_rate*slope_m\n",
    "            #slope_m = np.zeros(l)\n",
    "    return m\n",
    "\n",
    "def cost(x, y, m):\n",
    "    return ((y-(x.dot(m)))**2).mean()\n",
    "\n",
    "def gradient_descent(x,y, learning_rate, num_iter):\n",
    "    m = np.zeros(x.shape[1])\n",
    "    print('start: ', cost(x,y,m))\n",
    "    for i in range(num_iter):\n",
    "        m = step_gradient(x,y, learning_rate, m)\n",
    "        if i%10 == 0:\n",
    "            print(i, \" : \", cost(x,y,m))\n",
    "    return m\n",
    "\n",
    "def run(x,y):\n",
    "    learning_rate = 0.1\n",
    "    num_iter = 1000\n",
    "    m = gradient_descent(x,y,learning_rate,num_iter)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.genfromtxt('Gradient Descent-Combined_Cycle_Power_Plant_Train.csv', delimiter=',')\n",
    "x_train = dataset[:,:-1]\n",
    "y_train = dataset[:,-1]\n",
    "x_test = np.genfromtxt('Gradient Descent-Combined_Cycle_Power_Plant_Test.csv', delimiter=',')\n",
    "df_train = pd.DataFrame(x_train)\n",
    "df_test = pd.DataFrame(x_test)\n",
    "\n",
    "i = 0\n",
    "n = len(df_train.columns)\n",
    "l = df_train.columns\n",
    "while i < n:\n",
    "    j = i\n",
    "    while j < n:\n",
    "        df_train[str(l[i]) + '*' + str(l[j])] = df_train[l[i]]*df_train[l[j]]\n",
    "        j += 1\n",
    "    i += 1\n",
    "    \n",
    "i = 0\n",
    "n = len(df_test.columns)\n",
    "l = df_test.columns\n",
    "while i < n:\n",
    "    j = i\n",
    "    while j < n:\n",
    "        df_test[str(l[i]) + '*' + str(l[j])] = df_test[l[i]]*df_test[l[j]]\n",
    "        j += 1\n",
    "    i += 1\n",
    "\n",
    "x_train = np.array(df_train)\n",
    "x_test = np.array(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2392, 14), (7176, 14))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# for i in range(len(x_train[0])):\n",
    "#     std = np.sqrt(((x_train[:,i] - x_train[:,i].mean())**2).mean())\n",
    "#     x_train[:, i] = (x_train[:, i] - x_train[:, i].mean())/ std\n",
    "\n",
    "# for i in range(len(x_test[0])):\n",
    "#     std = np.sqrt(((x_test[:,i] - x_test[:,i].mean())**2).mean())\n",
    "#     x_test[:, i] = (x_test[:, i] - x_test[:, i].mean())/ std\n",
    "\n",
    "#for i in range(len(x_train[0])):\n",
    "#    x_train[:, i] = (x_train[:, i] - x_train[:, i].mean()) / (max(x_train[:, i]) - min(x_train[:, i]))\n",
    "    \n",
    "#for i in range(len(x_test[0])):\n",
    "#    x_test[:, i] = (x_test[:, i] - x_test[:, i].mean()) / (max(x_test[:, i]) - min(x_test[:, i]))\n",
    "\n",
    "#for i in range(len(x_train[0])):\n",
    "#    x_train[:, i] = (x_train[:, i] - min(x_train[:, i])) / (max(x_train[:, i]) - min(x_train[:, i]))\n",
    "    \n",
    "#for i in range(len(x_test[0])):\n",
    "#    x_test[:, i] = (x_test[:, i] - min(x_test[:, i])) / (max(x_test[:, i]) - min(x_test[:, i]))\n",
    "\n",
    "# x_train = preprocessing.scale(x_train)\n",
    "# x_test = preprocessing.scale(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.insert(x_train, 0, 1, axis = 1)\n",
    "x_test = np.insert(x_test, 0, 1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  206801.35285512818\n",
      "0  :  132332.2853383264\n",
      "10  :  1546.4591718490108\n",
      "20  :  38.71413286173015\n",
      "30  :  20.9435430435767\n",
      "40  :  20.535679206229872\n",
      "50  :  20.385017886628198\n",
      "60  :  20.264795253107838\n",
      "70  :  20.162793249510848\n",
      "80  :  20.074089150789458\n",
      "90  :  19.995565897620818\n",
      "100  :  19.925041319291026\n",
      "110  :  19.860938795927108\n",
      "120  :  19.802102920421707\n",
      "130  :  19.747677463498402\n",
      "140  :  19.69702021695152\n",
      "150  :  19.649642696148536\n",
      "160  :  19.60516726438213\n",
      "170  :  19.563296595484978\n",
      "180  :  19.523791899146712\n",
      "190  :  19.486457374879315\n",
      "200  :  19.45112909513685\n",
      "210  :  19.41766703902891\n",
      "220  :  19.385949368034197\n",
      "230  :  19.355868297967135\n",
      "240  :  19.327327108213037\n",
      "250  :  19.300237961954892\n",
      "260  :  19.274520305412953\n",
      "270  :  19.250099681130322\n",
      "280  :  19.226906837956076\n",
      "290  :  19.20487705421902\n",
      "300  :  19.183949614638045\n",
      "310  :  19.164067398610193\n",
      "320  :  19.14517654967039\n",
      "330  :  19.12722620455726\n",
      "340  :  19.11016826646395\n",
      "350  :  19.093957211423866\n",
      "360  :  19.078549919890943\n",
      "370  :  19.063905527789753\n",
      "380  :  19.04998529288685\n",
      "390  :  19.036752473460997\n",
      "400  :  19.02417221705316\n",
      "410  :  19.012211457650118\n",
      "420  :  19.00083882006926\n",
      "430  :  18.99002453060563\n",
      "440  :  18.97974033321747\n",
      "450  :  18.969959410679362\n",
      "460  :  18.960656310245664\n",
      "470  :  18.95180687344949\n",
      "480  :  18.94338816972275\n",
      "490  :  18.93537843357038\n",
      "500  :  18.92775700506528\n",
      "510  :  18.920504273458043\n",
      "520  :  18.913601623717135\n",
      "530  :  18.907031385831633\n",
      "540  :  18.900776786722727\n",
      "550  :  18.89482190462198\n",
      "560  :  18.88915162578464\n",
      "570  :  18.883751603413728\n",
      "580  :  18.878608218680235\n",
      "590  :  18.8737085437295\n",
      "600  :  18.869040306571684\n",
      "610  :  18.864591857759322\n",
      "620  :  18.860352138760113\n",
      "630  :  18.85631065193821\n",
      "640  :  18.852457432062035\n",
      "650  :  18.848783019260356\n",
      "660  :  18.845278433353368\n",
      "670  :  18.84193514948808\n",
      "680  :  18.838745075012124\n",
      "690  :  18.835700527522796\n",
      "700  :  18.83279421403153\n",
      "710  :  18.83001921118707\n",
      "720  :  18.827368946503697\n",
      "730  :  18.824837180543003\n",
      "740  :  18.822417990001412\n",
      "750  :  18.820105751656538\n",
      "760  :  18.817895127129567\n",
      "770  :  18.815781048421698\n",
      "780  :  18.81375870418543\n",
      "790  :  18.811823526693335\n",
      "800  :  18.809971179468914\n",
      "810  :  18.808197545545895\n",
      "820  :  18.806498716324025\n",
      "830  :  18.804870980990852\n",
      "840  :  18.803310816481275\n",
      "850  :  18.80181487794676\n",
      "860  :  18.800379989708997\n",
      "870  :  18.799003136673154\n",
      "880  :  18.797681456177088\n",
      "890  :  18.79641223025499\n",
      "900  :  18.795192878293527\n",
      "910  :  18.794020950061686\n",
      "920  :  18.792894119094015\n",
      "930  :  18.791810176410575\n",
      "940  :  18.790767024555294\n",
      "950  :  18.78976267193788\n",
      "960  :  18.788795227462277\n",
      "970  :  18.787862895428763\n",
      "980  :  18.786963970694423\n",
      "990  :  18.786096834079697\n"
     ]
    }
   ],
   "source": [
    "m = run(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = x_test.dot(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('CCPP_y_pred.csv', y_pred, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
